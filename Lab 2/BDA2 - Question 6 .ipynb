{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Assignment 6__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Compare the average monthly temperature (find the difference) in the period 1950-2014 for all stations in Östergotland with long-term monthly averages in the period of 1950-1980. Make a plot of your results.\n",
    "\n",
    "__HINT:__ The __first step__ is to find the monthly averages for each station. In the __next step__, you can average over all stations to acquire the average temperature for a specific year and month. This RDD/Data Frame can be used to compute the long-term average by averaging over all the years in the interval.\n",
    "\n",
    "The output should contain the following information:\n",
    "__Year, month, difference__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each question include the following data in the report and sort it as shown:\n",
    "- year, month, difference ORDER BY year DESC, month DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-1-ec3c098af780>:5 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-ec3c098af780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSQLContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    312\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 314\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    315\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-1-ec3c098af780>:5 "
     ]
    }
   ],
   "source": [
    "# create the setup\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, Row  \n",
    "from pyspark.sql import functions as F\n",
    "sc =SparkContext()\n",
    "sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, round, upper\n",
    "from  pyspark.sql.functions import abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_unifolder_temp_tiny = \"/Users/phillipholscher/OneDrive - Linköpings universitet/LiU/Statistics and Machine Learning/Spring19T2/Big Data Analytics/Labs/Lab 2/temperature-readings-tiny.csv\"\n",
    "path_unifolder_stations = \"/Users/phillipholscher/OneDrive - Linköpings universitet/LiU/Statistics and Machine Learning/Spring19T2/Big Data Analytics/Labs/Lab 2/stations-Ostergotland.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Temp=6.8, date='2013-11-01', day='01', month='11', quality='G', station='102170', time='06:00:00', year='2013'),\n",
       " Row(Temp=3.8, date='2013-11-01', day='01', month='11', quality='G', station='102170', time='18:00:00', year='2013'),\n",
       " Row(Temp=5.8, date='2013-11-02', day='02', month='11', quality='G', station='102170', time='06:00:00', year='2013'),\n",
       " Row(Temp=-1.1, date='2013-11-02', day='02', month='11', quality='G', station='102170', time='18:00:00', year='2013'),\n",
       " Row(Temp=-0.2, date='2013-11-03', day='03', month='11', quality='G', station='102170', time='06:00:00', year='2013'),\n",
       " Row(Temp=5.6, date='2013-11-03', day='03', month='11', quality='G', station='102170', time='18:00:00', year='2013'),\n",
       " Row(Temp=6.5, date='2013-11-04', day='04', month='11', quality='G', station='102170', time='06:00:00', year='2013'),\n",
       " Row(Temp=5.1, date='2013-11-04', day='04', month='11', quality='G', station='102170', time='18:00:00', year='2013'),\n",
       " Row(Temp=4.2, date='2013-11-05', day='05', month='11', quality='G', station='102170', time='06:00:00', year='2013'),\n",
       " Row(Temp=3.2, date='2013-11-05', day='05', month='11', quality='G', station='102170', time='18:00:00', year='2013')]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read and create rdd, this needs to be tranfsormed to data frame later on\n",
    "temps = sc.textFile(path_unifolder_temp_tiny)\n",
    "parts_temps = temps.map(lambda l:l.split(\";\"))\n",
    "tempReadings = parts_temps.map(lambda p: Row(station=p[0],  date=p[1], year=p[1].split(\"-\")[0], month=p[1].split(\"-\")[1], day=p[1].split(\"-\")[2], time=p[2],  Temp=float(p[3]), quality=p[4]))\n",
    "tempReadings.take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---+-----+-------+-------+--------+----+\n",
      "|Temp|      date|day|month|quality|station|    time|year|\n",
      "+----+----------+---+-----+-------+-------+--------+----+\n",
      "| 6.8|2013-11-01| 01|   11|      G| 102170|06:00:00|2013|\n",
      "| 3.8|2013-11-01| 01|   11|      G| 102170|18:00:00|2013|\n",
      "| 5.8|2013-11-02| 02|   11|      G| 102170|06:00:00|2013|\n",
      "|-1.1|2013-11-02| 02|   11|      G| 102170|18:00:00|2013|\n",
      "|-0.2|2013-11-03| 03|   11|      G| 102170|06:00:00|2013|\n",
      "| 5.6|2013-11-03| 03|   11|      G| 102170|18:00:00|2013|\n",
      "| 6.5|2013-11-04| 04|   11|      G| 102170|06:00:00|2013|\n",
      "| 5.1|2013-11-04| 04|   11|      G| 102170|18:00:00|2013|\n",
      "| 4.2|2013-11-05| 05|   11|      G| 102170|06:00:00|2013|\n",
      "| 3.2|2013-11-05| 05|   11|      G| 102170|18:00:00|2013|\n",
      "+----+----------+---+-----+-------+-------+--------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a data frame from rdd\n",
    "schemaTempReadings =  sqlContext.createDataFrame(tempReadings)\n",
    "schemaTempReadings.registerTempTable(\"tempReadings\")\n",
    "schemaTempReadings.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|                name|station|\n",
      "+--------------------+-------+\n",
      "|             Örberga|  84260|\n",
      "|           Västra Ny|  85630|\n",
      "|         Kettstaka A|  85460|\n",
      "|            Godegård|  85450|\n",
      "|          Zinkgruvan|  85490|\n",
      "|          Kärnskogen|  85650|\n",
      "|            Kvarn Mo|  85390|\n",
      "|            Finspång|  85410|\n",
      "|          Simonstorp|  86470|\n",
      "|         Stavsjö Aut|  86440|\n",
      "|Kolmården-Strömsf...|  86420|\n",
      "|     Norrköping-SMHI|  86340|\n",
      "|Norrköping-Kungsä...|  86350|\n",
      "|          Norrköping|  86360|\n",
      "|    Norrköping-Sörby|  86370|\n",
      "|               Holma|  86200|\n",
      "|            Marviken|  86330|\n",
      "|          Harstena A|  87140|\n",
      "|            Harstena|  87150|\n",
      "|        Valdemarsvik|  86130|\n",
      "|             Falerum|  86090|\n",
      "|            Skärkind|  85280|\n",
      "|           Linköping|  85250|\n",
      "|           Malmslätt|  85240|\n",
      "|          Västerlösa|  85270|\n",
      "|              Öjebro|  85220|\n",
      "|           Herrberga|  85210|\n",
      "|             Härsnäs|  85180|\n",
      "|          Malexander|  85040|\n",
      "|        Malexander A|  85050|\n",
      "|              Horn A|  75520|\n",
      "|         Bjärka-Säby|  85160|\n",
      "|            Adelsnäs|  85600|\n",
      "|          Åtvidaberg|  85130|\n",
      "+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read and create rdd, this needs to be tranfsormed to data frame later on\n",
    "stations = sc.textFile(path_unifolder_stations)\n",
    "# create DataFrame from RDD\n",
    "parts_stations = stations.map(lambda a: a.split(';'))\n",
    "schemaStationsOestergotland = parts_stations.map(lambda x: Row(station = x[0], name = x[1]))\n",
    "schemaStationsOestergotland = sqlContext.createDataFrame(schemaStationsOestergotland)\n",
    "\n",
    "schemaStationsOestergotland.show(100) # this list is with all stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+---+-----+-------+----+----+----+\n",
      "|station|Temp|date|day|month|quality|time|year|name|\n",
      "+-------+----+----+---+-----+-------+----+----+----+\n",
      "+-------+----+----+---+-----+-------+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join to filter for ostg stations\n",
    "schemaTempReadings2 = schemaTempReadings.join(schemaStationsOestergotland, 'station', 'inner')\n",
    "schemaTempReadings2.show(10)\n",
    "# the result would be empty - there for we continue without filter by stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__First step__ is to find the monthly averages for each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+---+----+\n",
      "|station|year|month|day|Temp|\n",
      "+-------+----+-----+---+----+\n",
      "| 102170|2013|   11| 01| 6.8|\n",
      "| 102170|2013|   11| 01| 3.8|\n",
      "| 102170|2013|   11| 02| 5.8|\n",
      "| 102170|2013|   11| 02|-1.1|\n",
      "| 102170|2013|   11| 03|-0.2|\n",
      "| 102170|2013|   11| 03| 5.6|\n",
      "| 102170|2013|   11| 04| 6.5|\n",
      "| 102170|2013|   11| 04| 5.1|\n",
      "| 102170|2013|   11| 05| 4.2|\n",
      "| 102170|2013|   11| 05| 3.2|\n",
      "+-------+----+-----+---+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter for given time interval\n",
    "tempReadings_filtered_2014 = schemaTempReadings\\\n",
    ".select([\"station\", \"year\", \"month\", \"day\", \"Temp\"])\\\n",
    ".filter((schemaTempReadings[\"year\"] >= 1950) & (schemaTempReadings[\"year\"] <= 2014))\n",
    "\n",
    "tempReadings_filtered_2014.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------+--------+--------+\n",
      "|year|month|station|Temp_max|Temp_min|\n",
      "+----+-----+-------+--------+--------+\n",
      "|1959|   08| 102190|    28.2|     5.3|\n",
      "|1959|   12| 102190|     5.0|   -18.8|\n",
      "|1956|   01| 102190|     4.0|   -30.0|\n",
      "|1959|   07| 102190|    27.4|     4.8|\n",
      "|2014|   01| 102170|     6.6|   -19.6|\n",
      "|1956|   06| 102190|    26.0|     3.8|\n",
      "|1956|   08| 102190|    19.1|     3.9|\n",
      "|1958|   02| 102190|     2.9|   -27.9|\n",
      "|1958|   03| 102190|     5.7|   -20.0|\n",
      "|1960|   07| 102190|    25.0|     6.0|\n",
      "+----+-----+-------+--------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to calculate the monthly avg for each station do we need the max and min temp for each month and station\n",
    "schemaTempReadings_max_min_2014 = tempReadings_filtered_2014.groupBy(\"year\", \"month\", \"station\")\\\n",
    ".agg(F.max(\"Temp\").alias(\"Temp_max\"),F.min(\"Temp\").alias(\"Temp_min\"))\n",
    "\n",
    "schemaTempReadings_max_min_2014.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the avg temp as in the exercise asked for\n",
    "def avg_temp(max_temp, min_temp):\n",
    "    avg = (max_temp + min_temp)/2.0\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------+--------+--------+--------+\n",
      "|year|month|station|Temp_max|Temp_min|Temp_avg|\n",
      "+----+-----+-------+--------+--------+--------+\n",
      "|1959|   08| 102190|    28.2|     5.3|    16.8|\n",
      "|1959|   12| 102190|     5.0|   -18.8|    -6.9|\n",
      "|1956|   01| 102190|     4.0|   -30.0|   -13.0|\n",
      "|1959|   07| 102190|    27.4|     4.8|    16.1|\n",
      "|2014|   01| 102170|     6.6|   -19.6|    -6.5|\n",
      "|1956|   06| 102190|    26.0|     3.8|    14.9|\n",
      "|1956|   08| 102190|    19.1|     3.9|    11.5|\n",
      "|1958|   02| 102190|     2.9|   -27.9|   -12.5|\n",
      "|1958|   03| 102190|     5.7|   -20.0|    -7.2|\n",
      "|1960|   07| 102190|    25.0|     6.0|    15.5|\n",
      "+----+-----+-------+--------+--------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute the avg monthly temp for each station\n",
    "schemaTempReadings_avg_2014 = schemaTempReadings_max_min_2014\\\n",
    ".withColumn(\"Temp_avg\", \n",
    "            round(avg_temp(schemaTempReadings_max_min_2014[\"Temp_max\"],\n",
    "                           schemaTempReadings_max_min_2014[\"Temp_min\"]),1))\n",
    "schemaTempReadings_avg_2014.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+--------+\n",
      "|year|month|Temp_avg|\n",
      "+----+-----+--------+\n",
      "|2014|   07|    20.4|\n",
      "|1960|   06|    17.1|\n",
      "|1959|   08|    16.8|\n",
      "|1959|   07|    16.1|\n",
      "|1958|   07|    16.1|\n",
      "|1960|   07|    15.5|\n",
      "|1960|   08|    15.4|\n",
      "|1956|   07|    15.3|\n",
      "|2014|   06|    15.2|\n",
      "|1957|   07|    15.2|\n",
      "+----+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sort the avg temp \n",
    "schemaTempReadings_avg_ordered_2014 = schemaTempReadings_avg_2014.select([\"year\", \"month\", \"Temp_avg\"])\\\n",
    ".orderBy(\"Temp_avg\", ascending = False)\n",
    "\n",
    "schemaTempReadings_avg_ordered_2014.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Second step__  average over all stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+--------+\n",
      "|year|month|Temp_avg|\n",
      "+----+-----+--------+\n",
      "|1960|   06|    17.1|\n",
      "|1959|   08|    16.8|\n",
      "|1959|   07|    16.1|\n",
      "|1958|   07|    16.1|\n",
      "|1960|   07|    15.5|\n",
      "|1960|   08|    15.4|\n",
      "|1956|   07|    15.3|\n",
      "|1957|   07|    15.2|\n",
      "|1956|   06|    14.9|\n",
      "|1959|   06|    14.7|\n",
      "+----+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute the long term monthly avg\n",
    "\n",
    "# filter >= 1950 & <= 1980\n",
    "long_term_month_avg_filterd = schemaTempReadings_avg_ordered_2014.filter((schemaTempReadings_avg_ordered_2014[\"year\"] >= 1950) &\n",
    "                                                     (schemaTempReadings_avg_ordered_2014[\"year\"] <= 1980))\n",
    "long_term_month_avg_filterd.show(10) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "|month|LT_avg_monthly|\n",
      "+-----+--------------+\n",
      "|   07|          15.6|\n",
      "|   11|          -2.4|\n",
      "|   01|          -9.4|\n",
      "|   09|           9.5|\n",
      "|   05|           9.9|\n",
      "|   08|          14.3|\n",
      "|   03|          -2.5|\n",
      "|   02|          -9.3|\n",
      "|   06|          14.0|\n",
      "|   10|           3.6|\n",
      "+-----+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# avg over all month\n",
    "long_term_month_avg = long_term_month_avg_filterd\\\n",
    ".groupBy(\"month\").agg(round(F.avg(\"Temp_avg\"),1).alias(\"LT_avg_monthly\"))\n",
    "\n",
    "long_term_month_avg.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the differences\n",
    "def differences(Temp_avg, montly_avg):\n",
    "    return abs(Temp_avg - montly_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+--------+--------------+\n",
      "|month|year|Temp_avg|LT_avg_monthly|\n",
      "+-----+----+--------+--------------+\n",
      "|   07|2014|    20.4|          15.6|\n",
      "|   07|1959|    16.1|          15.6|\n",
      "|   07|1958|    16.1|          15.6|\n",
      "|   07|1960|    15.5|          15.6|\n",
      "|   07|1956|    15.3|          15.6|\n",
      "|   07|1957|    15.2|          15.6|\n",
      "|   11|2014|     1.2|          -2.4|\n",
      "|   11|1958|     0.4|          -2.4|\n",
      "|   11|1959|    -0.9|          -2.4|\n",
      "|   11|1960|    -1.4|          -2.4|\n",
      "+-----+----+--------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to compute the differences we have to join the data frames first\n",
    "temp_differ = schemaTempReadings_avg_ordered_2014.join(long_term_month_avg, \"month\", \"inner\")\n",
    "\n",
    "temp_differ.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+--------+--------------+-----------+\n",
      "|month|year|Temp_avg|LT_avg_monthly|differences|\n",
      "+-----+----+--------+--------------+-----------+\n",
      "|   12|2014|    -9.4|          -6.5|        2.9|\n",
      "|   11|2014|     1.2|          -2.4|        3.6|\n",
      "|   10|2014|     5.1|           3.6|        1.5|\n",
      "|   09|2014|     7.7|           9.5|        1.8|\n",
      "|   08|2014|    14.8|          14.3|        0.5|\n",
      "|   07|2014|    20.4|          15.6|        4.8|\n",
      "|   06|2014|    15.2|          14.0|        1.2|\n",
      "|   05|2014|    12.6|           9.9|        2.7|\n",
      "|   04|2014|     5.2|           3.4|        1.8|\n",
      "|   03|2014|     1.7|          -2.5|        4.2|\n",
      "+-----+----+--------+--------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute the temp difference\n",
    "temp_differ = temp_differ.withColumn(\"differences\",\n",
    "                                     round(differences(temp_differ[\"Temp_avg\"],\n",
    "                                                 temp_differ[\"LT_avg_monthly\"]),1))\\\n",
    ".orderBy([\"year\", \"month\"], ascending = False)\n",
    "temp_differ.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+\n",
      "|year|month|differences|\n",
      "+----+-----+-----------+\n",
      "|2014|   12|        2.9|\n",
      "|2014|   11|        3.6|\n",
      "|2014|   10|        1.5|\n",
      "|2014|   09|        1.8|\n",
      "|2014|   08|        0.5|\n",
      "|2014|   07|        4.8|\n",
      "|2014|   06|        1.2|\n",
      "|2014|   05|        2.7|\n",
      "|2014|   04|        1.8|\n",
      "|2014|   03|        4.2|\n",
      "+----+-----+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the required result\n",
    "temp_differ_result = temp_differ.select(\"year\", \"month\", \"differences\")\n",
    "\n",
    "temp_differ_result.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Github version*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the temperature data\n",
    "rdd = sc.textFile(\"/Users/phillipholscher/OneDrive - Linköpings universitet/LiU/Statistics and Machine Learning/Spring19T2/Big Data Analytics/Labs/Lab 2/temperature-readings-tiny.csv\")\n",
    "# create DataFrame from RDD\n",
    "parts = rdd.map(lambda a: a.split(';'))\n",
    "tempReadingsRow = parts.map(lambda x: (x[0], x[1], int(x[1].split(\"-\")[0]), int(x[1].split(\"-\")[1]), x[2], float(x[3]), x[4]))\n",
    "tempReadingsString = [\"station\", \"date\", \"year\", \"month\", \"time\", \"value\", \"quality\"]\n",
    "schemaTempReadings = sqlContext.createDataFrame(tempReadingsRow, tempReadingsString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the Ostergotland stations data\n",
    "rdd = sc.textFile(\"/Users/phillipholscher/OneDrive - Linköpings universitet/LiU/Statistics and Machine Learning/Spring19T2/Big Data Analytics/Labs/Lab 2/stations-Ostergotland.csv\")\n",
    "# create DataFrame from RDD\n",
    "parts = rdd.map(lambda a: a.split(';'))\n",
    "statOstRow = parts.map(lambda x: (x[0], x[1]))\n",
    "statOstString = [\"station\", \"name\"]\n",
    "schemaStatOst = sqlContext.createDataFrame(statOstRow, statOstString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to filter for ostg stations\n",
    "schemaTempReadings = schemaTempReadings.join(schemaStatOst, 'station', 'inner')\n",
    "schemaTempReadings.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**long term monthly avg - version 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+---+-----+-------+-------+--------+----+\n",
      "|Temp|      date|day|month|quality|station|    time|year|\n",
      "+----+----------+---+-----+-------+-------+--------+----+\n",
      "|14.5|1955-09-01| 01|   09|      Y| 102190|06:00:00|1955|\n",
      "|19.8|1955-09-01| 01|   09|      Y| 102190|12:00:00|1955|\n",
      "|15.2|1955-09-01| 01|   09|      Y| 102190|18:00:00|1955|\n",
      "|11.6|1955-09-02| 02|   09|      Y| 102190|06:00:00|1955|\n",
      "|15.8|1955-09-02| 02|   09|      Y| 102190|12:00:00|1955|\n",
      "|12.3|1955-09-02| 02|   09|      Y| 102190|18:00:00|1955|\n",
      "|11.5|1955-09-03| 03|   09|      Y| 102190|06:00:00|1955|\n",
      "|14.5|1955-09-03| 03|   09|      Y| 102190|12:00:00|1955|\n",
      "|13.4|1955-09-03| 03|   09|      Y| 102190|18:00:00|1955|\n",
      "| 7.7|1955-09-04| 04|   09|      Y| 102190|06:00:00|1955|\n",
      "+----+----------+---+-----+-------+-------+--------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute the long term monthly avg\n",
    "\n",
    "# filter >= 1950 & <= 1980\n",
    "long_term_month_avg_filterd_version2 = schemaTempReadings.filter((schemaTempReadings[\"year\"] >= 1950) &\n",
    "                                                     (schemaTempReadings[\"year\"] <= 1980))\n",
    "long_term_month_avg_filterd_version2.show(10) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------+--------+\n",
      "|year|month|station|Temp_avg|\n",
      "+----+-----+-------+--------+\n",
      "|1959|   08| 102190|    15.7|\n",
      "|1959|   12| 102190|    -2.4|\n",
      "|1956|   01| 102190|    -9.3|\n",
      "|1959|   07| 102190|    17.1|\n",
      "|1956|   06| 102190|    13.0|\n",
      "|1956|   08| 102190|    11.5|\n",
      "|1958|   02| 102190|    -9.7|\n",
      "|1958|   03| 102190|    -6.3|\n",
      "|1960|   07| 102190|    14.2|\n",
      "|1958|   08| 102190|    13.2|\n",
      "+----+-----+-------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# avg over all month\n",
    "long_term_month_avg_version2 = long_term_month_avg_filterd_version2\\\n",
    ".groupBy('year','month','station').agg(round(F.avg('Temp'),1).alias('Temp_avg'))\n",
    "\n",
    "long_term_month_avg_version2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+\n",
      "|month|Temp_avg_monthly|\n",
      "+-----+----------------+\n",
      "|   12|            -4.0|\n",
      "|   11|            -0.4|\n",
      "|   10|             4.5|\n",
      "|   09|             9.5|\n",
      "|   08|            13.5|\n",
      "|   07|            15.6|\n",
      "|   06|            13.9|\n",
      "|   05|             9.6|\n",
      "|   04|             2.9|\n",
      "|   03|            -2.0|\n",
      "|   02|            -6.6|\n",
      "|   01|            -7.3|\n",
      "+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "long_term_month_avg_version2 = long_term_month_avg_version2\\\n",
    ".groupBy('month').agg(round(F.avg('Temp_avg'),1).alias(\"Temp_avg_monthly\"))\\\n",
    ".orderBy(\"month\", ascending = False)\n",
    "\n",
    "long_term_month_avg_version2.show(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+\n",
      "|year|month|differences|\n",
      "+----+-----+-----------+\n",
      "|2014|   12|        5.4|\n",
      "|2014|   11|        1.6|\n",
      "|2014|   10|        0.6|\n",
      "|2014|   09|        1.8|\n",
      "|2014|   08|        1.3|\n",
      "|2014|   07|        4.8|\n",
      "|2014|   06|        1.3|\n",
      "|2014|   05|        3.0|\n",
      "|2014|   04|        2.3|\n",
      "|2014|   03|        3.7|\n",
      "+----+-----+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to compute the differences we have to join the data frames first\n",
    "temp_differ_v2 = schemaTempReadings_avg_ordered_2014.join(long_term_month_avg_version2, \"month\", \"inner\")\n",
    "\n",
    "\n",
    "# compute the temp difference\n",
    "temp_differ_v2 = temp_differ_v2.withColumn(\"differences\",\n",
    "                                     round(differences(temp_differ_v2[\"Temp_avg\"],\n",
    "                                                 temp_differ_v2[\"Temp_avg_monthly\"]),1))\\\n",
    ".orderBy([\"year\", \"month\"], ascending = False)\n",
    "\n",
    "# show the required result\n",
    "temp_differ_result_v2 = temp_differ_v2.select(\"year\", \"month\", \"differences\")\n",
    "\n",
    "temp_differ_result_v2.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
