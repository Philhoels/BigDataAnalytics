{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext,SparkConf\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "T= sc.textFile(\"C:/Users/quartermaine/Documents/Big Data Analytics Labs/temperature-readings-tiny.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = T.map(lambda line: line.split(\";\"))\n",
    "\n",
    "year_temperature = lines.map(lambda x: (x[1][0:4], float(x[3])))\n",
    "\n",
    "year_temperature = year_temperature.filter(lambda x: int(x[0]) >= 1950 and int(x[0]) <= 2014)\n",
    "\n",
    "max_temperatures= year_temperature.reduceByKey(lambda x,y :x if x>=y else y)\n",
    "\n",
    "max_temperaturesSorted=max_temperatures.sortBy(ascending=False,keyfunc=lambda k:k[1])\n",
    "\n",
    "min_temperatures= year_temperature.reduceByKey(lambda x,y :x if x<=y else y)\n",
    "\n",
    "min_temperaturesSorted=min_temperatures.sortBy(ascending=True,keyfunc=lambda k:k[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Table with max temperatures per year---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('2014', 29.1),\n",
       " ('1960', 29.0),\n",
       " ('1959', 28.2),\n",
       " ('1958', 28.1),\n",
       " ('1956', 26.0),\n",
       " ('1957', 25.2),\n",
       " ('1955', 20.4),\n",
       " ('1961', 19.0),\n",
       " ('2013', 10.2)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"----Table with max temperatures per year---\")\n",
    "max_temperaturesSorted.take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Table with min temperatures per year---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('1956', -30.0),\n",
       " ('1960', -28.3),\n",
       " ('1958', -27.9),\n",
       " ('1955', -26.2),\n",
       " ('2014', -24.3),\n",
       " ('1961', -23.5),\n",
       " ('1959', -23.2),\n",
       " ('1957', -19.9),\n",
       " ('2013', -13.3)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"----Table with min temperatures per year---\")\n",
    "min_temperaturesSorted.take(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_temp = lines.map(lambda x: (x[1][0:4],( float(x[3]),x[0])))\n",
    "\n",
    "year_temp = year_temp.filter(lambda x: int(x[0]) >= 1950 and int(x[0]) <= 2014)\n",
    "\n",
    "#############################\n",
    "max_temperatures1= year_temp.reduceByKey(lambda x,y :x if x>=y else y)\n",
    "\n",
    "max_temperaturesSorted1=max_temperatures1.sortBy(ascending=False,keyfunc=lambda k:k[1][0])\n",
    "\n",
    "t=max_temperaturesSorted1.map(lambda x: (x[0], float(x[1][0]),x[1][1]))\n",
    "\n",
    "#############################\n",
    "\n",
    "min_temperatures1= year_temp.reduceByKey(lambda x,y :x if x<=y else y)\n",
    "\n",
    "min_temperaturesSorted1=min_temperatures1.sortBy(ascending=True,keyfunc=lambda k:k[1][0])\n",
    "\n",
    "t1=min_temperaturesSorted1.map(lambda x: (x[0], float(x[1][0]),x[1][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Table with max temperatures per year---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('2014', 29.1, '102170'),\n",
       " ('1960', 29.0, '102190'),\n",
       " ('1959', 28.2, '102190'),\n",
       " ('1958', 28.1, '102190'),\n",
       " ('1956', 26.0, '102190'),\n",
       " ('1957', 25.2, '102190'),\n",
       " ('1955', 20.4, '102190'),\n",
       " ('1961', 19.0, '102190'),\n",
       " ('2013', 10.2, '102170')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"----Table with max temperatures per year---\")\n",
    "t.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Table with min temperatures per year---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('1956', -30.0, '102190'),\n",
       " ('1960', -28.3, '102190'),\n",
       " ('1958', -27.9, '102190'),\n",
       " ('1955', -26.2, '102190'),\n",
       " ('2014', -24.3, '102170'),\n",
       " ('1961', -23.5, '102190'),\n",
       " ('1959', -23.2, '102190'),\n",
       " ('1957', -19.9, '102190'),\n",
       " ('2013', -13.3, '102170')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"----Table with min temperatures per year---\")\n",
    "t1.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_number</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102170</td>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>6.8</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102170</td>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>3.8</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102170</td>\n",
       "      <td>2013-11-02</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>5.8</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102170</td>\n",
       "      <td>2013-11-02</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102170</td>\n",
       "      <td>2013-11-03</td>\n",
       "      <td>06:00:00</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_number        date      time  Temperature quality\n",
       "0          102170  2013-11-01  06:00:00          6.8       G\n",
       "1          102170  2013-11-01  18:00:00          3.8       G\n",
       "2          102170  2013-11-02  06:00:00          5.8       G\n",
       "3          102170  2013-11-02  18:00:00         -1.1       G\n",
       "4          102170  2013-11-03  06:00:00         -0.2       G"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dat=pd.read_csv(\"temperature-readings-tiny.csv\",sep=';',header=None)\n",
    "dat.columns = ['station_number', 'date','time','Temperature','quality']\n",
    "print(\"first 5 rows\")\n",
    "dat.head(5)\n",
    "# print(\"column names\")\n",
    "# dat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_number</th>\n",
       "      <th>date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102170</td>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102170</td>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102170</td>\n",
       "      <td>2013-11-02</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102170</td>\n",
       "      <td>2013-11-02</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102170</td>\n",
       "      <td>2013-11-03</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_number        date  Temperature  year\n",
       "0          102170  2013-11-01          6.8  2013\n",
       "1          102170  2013-11-01          3.8  2013\n",
       "2          102170  2013-11-02          5.8  2013\n",
       "3          102170  2013-11-02         -1.1  2013\n",
       "4          102170  2013-11-03         -0.2  2013"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=dat[['station_number','date','Temperature']]\n",
    "dt['year'] = pd.DatetimeIndex(dt['date']).year\n",
    "dt.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_number</th>\n",
       "      <th>year</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102170</td>\n",
       "      <td>2013</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102170</td>\n",
       "      <td>2013</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102170</td>\n",
       "      <td>2013</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102170</td>\n",
       "      <td>2013</td>\n",
       "      <td>-1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102170</td>\n",
       "      <td>2013</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_number  year  Temperature\n",
       "0          102170  2013          6.8\n",
       "1          102170  2013          3.8\n",
       "2          102170  2013          5.8\n",
       "3          102170  2013         -1.1\n",
       "4          102170  2013         -0.2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT=dt[['station_number','year','Temperature']]\n",
    "DT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>station_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <th>102190</th>\n",
       "      <td>-26.2</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <th>102190</th>\n",
       "      <td>-30.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <th>102190</th>\n",
       "      <td>-19.9</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <th>102190</th>\n",
       "      <td>-27.9</td>\n",
       "      <td>28.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <th>102190</th>\n",
       "      <td>-23.2</td>\n",
       "      <td>28.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <th>102190</th>\n",
       "      <td>-28.3</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <th>102190</th>\n",
       "      <td>-23.5</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <th>102170</th>\n",
       "      <td>-13.3</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <th>102170</th>\n",
       "      <td>-24.3</td>\n",
       "      <td>29.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <th>102170</th>\n",
       "      <td>-19.6</td>\n",
       "      <td>26.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <th>102170</th>\n",
       "      <td>-25.5</td>\n",
       "      <td>25.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Temperature      \n",
       "                            min   max\n",
       "year station_number                  \n",
       "1955 102190               -26.2  20.4\n",
       "1956 102190               -30.0  26.0\n",
       "1957 102190               -19.9  25.2\n",
       "1958 102190               -27.9  28.1\n",
       "1959 102190               -23.2  28.2\n",
       "1960 102190               -28.3  29.0\n",
       "1961 102190               -23.5  19.0\n",
       "2013 102170               -13.3  10.2\n",
       "2014 102170               -24.3  29.1\n",
       "2015 102170               -19.6  26.8\n",
       "2016 102170               -25.5  25.8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT.groupby(['year','station_number']).agg({'Temperature': ['min', 'max']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('1955', '09'), 55),\n",
       " (('1955', '10'), 23),\n",
       " (('1956', '03'), 4),\n",
       " (('1956', '04'), 7),\n",
       " (('1956', '05'), 60),\n",
       " (('1956', '06'), 92),\n",
       " (('1956', '07'), 108),\n",
       " (('1956', '08'), 84),\n",
       " (('1956', '09'), 54),\n",
       " (('1956', '10'), 17),\n",
       " (('1957', '03'), 1),\n",
       " (('1957', '04'), 13),\n",
       " (('1957', '05'), 46),\n",
       " (('1957', '06'), 72),\n",
       " (('1957', '07'), 109),\n",
       " (('1957', '08'), 96),\n",
       " (('1957', '09'), 43),\n",
       " (('1957', '10'), 9),\n",
       " (('1958', '04'), 4),\n",
       " (('1958', '05'), 40)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lines.map(lambda x: ( (x[1][0:4],x[1][5:7]),float(x[3]) ))\n",
    "\n",
    "y = y.filter(lambda x: int(x[0][0]) >= 1950 and int(x[0][0]) <= 2014)\n",
    "\n",
    "#############################\n",
    "tempsOver= y.filter(lambda x : x[1] >= 10)\n",
    "\n",
    "tempsOver_unpack=tempsOver.map(lambda x: ( (x[0][0], x[0][1]),1))\n",
    "\n",
    "tempsOver10=tempsOver_unpack.reduceByKey(lambda x,y : x+y).sortByKey() #x,y are the value of each key ,addeed up\n",
    "tempsOver10.take(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('1955', '09'), 55),\n",
       " (('1955', '10'), 23),\n",
       " (('1956', '03'), 4),\n",
       " (('1956', '04'), 7),\n",
       " (('1956', '05'), 60),\n",
       " (('1956', '06'), 92),\n",
       " (('1956', '07'), 108),\n",
       " (('1956', '08'), 84),\n",
       " (('1956', '09'), 54),\n",
       " (('1956', '10'), 17)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with one line \n",
    "sorted(tempsOver.countByKey().items())[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method distinct in module pyspark.rdd:\n",
      "\n",
      "distinct(numPartitions=None) method of pyspark.rdd.PipelinedRDD instance\n",
      "    Return a new RDD containing the distinct elements in this RDD.\n",
      "    \n",
      "    >>> sorted(sc.parallelize([1, 1, 2, 3]).distinct().collect())\n",
      "    [1, 2, 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tempsOver.distinct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('1955', '09'), 35),\n",
       " (('1955', '10'), 20),\n",
       " (('1956', '03'), 4),\n",
       " (('1956', '04'), 5),\n",
       " (('1956', '05'), 44),\n",
       " (('1956', '06'), 58),\n",
       " (('1956', '07'), 76),\n",
       " (('1956', '08'), 49),\n",
       " (('1956', '09'), 30),\n",
       " (('1956', '10'), 13)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with one line\n",
    "sorted(tempsOver.distinct().countByKey().items())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the influence of distinct \n",
    "# j = lines.map(lambda x: ( (x[1][0:4],x[1][5:7],x[1]),float(x[3]) ))\n",
    "\n",
    "# j = j.filter(lambda x: int(x[0][0]) == 1956 and int(x[0][1])==4 and x[1]>=10.)\n",
    "\n",
    "# j.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('2013', '11', '01', '102170'), 6.8),\n",
       " (('2013', '11', '01', '102170'), 3.8),\n",
       " (('2013', '11', '02', '102170'), 5.8),\n",
       " (('2013', '11', '02', '102170'), -1.1),\n",
       " (('2013', '11', '03', '102170'), -0.2),\n",
       " (('2013', '11', '03', '102170'), 5.6),\n",
       " (('2013', '11', '04', '102170'), 6.5),\n",
       " (('2013', '11', '04', '102170'), 5.1),\n",
       " (('2013', '11', '05', '102170'), 4.2),\n",
       " (('2013', '11', '05', '102170'), 3.2)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = lines.map(lambda x: ( (x[1][0:4],x[1][5:7],x[1][8:10],x[0]),float(x[3]) ))\n",
    "\n",
    "rdd = rdd.filter(lambda x: int(x[0][0]) >= 1960 and int(x[0][0]) <= 2014)\n",
    "\n",
    "#############################\n",
    "\n",
    "rdd=rdd.map(lambda x: ( (x[0][0],x[0][1],x[0][2], x[0][3]),float(x[1]) ) )\n",
    "\n",
    "rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('2014', '12', '31', '102170'), -7.05),\n",
       " (('2014', '12', '30', '102170'), -9.600000000000001),\n",
       " (('2014', '12', '29', '102170'), -12.8),\n",
       " (('2014', '12', '28', '102170'), -20.200000000000003),\n",
       " (('2014', '12', '27', '102170'), -21.05),\n",
       " (('2014', '12', '26', '102170'), -19.9),\n",
       " (('2014', '12', '25', '102170'), -18.65),\n",
       " (('2014', '12', '24', '102170'), -12.8),\n",
       " (('2014', '12', '23', '102170'), -11.850000000000001),\n",
       " (('2014', '12', '22', '102170'), -6.0),\n",
       " (('2014', '12', '21', '102170'), -10.0),\n",
       " (('2014', '12', '20', '102170'), -7.050000000000001),\n",
       " (('2014', '12', '19', '102170'), 0.20000000000000007),\n",
       " (('2014', '12', '18', '102170'), -3.2),\n",
       " (('2014', '12', '17', '102170'), -6.75),\n",
       " (('2014', '12', '16', '102170'), -0.45),\n",
       " (('2014', '12', '15', '102170'), 2.8),\n",
       " (('2014', '12', '14', '102170'), -1.2000000000000002),\n",
       " (('2014', '12', '13', '102170'), -1.85),\n",
       " (('2014', '12', '12', '102170'), 1.7000000000000002),\n",
       " (('2014', '12', '11', '102170'), 1.5),\n",
       " (('2014', '12', '10', '102170'), 1.75),\n",
       " (('2014', '12', '09', '102170'), -7.25),\n",
       " (('2014', '12', '08', '102170'), -2.9499999999999997),\n",
       " (('2014', '12', '07', '102170'), 3.8),\n",
       " (('2014', '12', '06', '102170'), -3.2),\n",
       " (('2014', '12', '05', '102170'), -0.35),\n",
       " (('2014', '12', '04', '102170'), -3.3),\n",
       " (('2014', '12', '03', '102170'), -2.7),\n",
       " (('2014', '12', '02', '102170'), -0.35000000000000003),\n",
       " (('2014', '12', '01', '102170'), -1.1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanRDD = (rdd\n",
    "           .mapValues(lambda x: (x, 1))\n",
    "           .reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1]))\n",
    "           .mapValues(lambda x: x[0]/x[1]))\n",
    "meanRDD.sortByKey(ascending=False).take(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('2014', '12', '102170'), -5.801612903225807),\n",
       " (('2014', '11', '102170'), 2.525),\n",
       " (('2014', '10', '102170'), 7.106451612903226),\n",
       " (('2014', '09', '102170'), 8.585),\n",
       " (('2014', '08', '102170'), 13.869354838709675),\n",
       " (('2014', '07', '102170'), 19.659677419354836),\n",
       " (('2014', '06', '102170'), 14.443333333333333),\n",
       " (('2014', '05', '102170'), 10.756451612903227),\n",
       " (('2014', '04', '102170'), 4.776666666666667),\n",
       " (('2014', '03', '102170'), 1.896774193548387),\n",
       " (('2014', '02', '102170'), 0.6749999999999999),\n",
       " (('2014', '01', '102170'), -4.106451612903226),\n",
       " (('2013', '12', '102170'), 0.7096774193548387),\n",
       " (('2013', '11', '102170'), -0.05166666666666663),\n",
       " (('1961', '05', '102190'), 10.61533333333333),\n",
       " (('1961', '04', '102190'), 4.507777777777778),\n",
       " (('1961', '03', '102190'), 2.708602150537634),\n",
       " (('1961', '02', '102190'), -2.1333333333333333),\n",
       " (('1961', '01', '102190'), -7.215053763440859),\n",
       " (('1960', '12', '102190'), -2.427419354838709),\n",
       " (('1960', '11', '102190'), -0.42999999999999994),\n",
       " (('1960', '10', '102190'), 2.0943548387096773),\n",
       " (('1960', '09', '102190'), 9.402222222222223),\n",
       " (('1960', '08', '102190'), 13.41989247311828),\n",
       " (('1960', '07', '102190'), 14.205645161290322),\n",
       " (('1960', '06', '102190'), 15.769722222222223),\n",
       " (('1960', '05', '102190'), 10.768548387096773),\n",
       " (('1960', '04', '102190'), 2.5100000000000002),\n",
       " (('1960', '03', '102190'), -2.2798387096774193),\n",
       " (('1960', '02', '102190'), -9.61810344827586),\n",
       " (('1960', '01', '102190'), -6.875)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanRDD.map(lambda x: ( (x[0][0],x[0][1],x[0][3]),x[1]) )\\\n",
    ".mapValues(lambda x: (x, 1))\\\n",
    ".reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1]))\\\n",
    ".mapValues(lambda x: x[0]/x[1]).sortByKey(ascending=False).take(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('102170', '2014-07-22'), 28.0),\n",
       " (('102170', '2014-07-23'), 29.1),\n",
       " (('102170', '2014-07-26'), 28.7),\n",
       " (('102170', '2014-07-29'), 25.5),\n",
       " (('102170', '2015-07-01'), 26.8)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = T.map(lambda line: line.split(\";\"))\n",
    "\n",
    "station_temperature = l.map(lambda x:( (x[0],x[1]) ,float(x[3])))\n",
    "\n",
    "#station_temperature = station_temperature.filter(lambda x: int(x[0]) >= 1950 and int(x[0]) <= 2014)\n",
    "\n",
    "max_temp_station= station_temperature.reduceByKey(lambda x,y :x if x>=y else y)\n",
    "\n",
    "max_temp_station=max_temp_station.filter(lambda x: x[1]>=25. and x[1]<=30.)\n",
    "\n",
    "max_temp_st=max_temp_station.map(lambda x: (x[0],float(x[1]) ))\n",
    "max_temp_st.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#station_temperature.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('105220', '1997-07-01'), 18.7),\n",
       " (('105220', '2004-02-04'), 10.0),\n",
       " (('106570', '1997-06-10'), 12.8),\n",
       " (('106570', '2004-07-19'), 15.5),\n",
       " (('108320', '2010-06-30'), 10.0),\n",
       " (('114140', '2009-07-30'), 10.7),\n",
       " (('114140', '2012-08-26'), 11.5),\n",
       " (('114410', '2013-07-31'), 12.2),\n",
       " (('122260', '2010-08-03'), 10.1),\n",
       " (('123060', '1996-06-17'), 11.9)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep=sc.textFile(\"C:/Users/quartermaine/Documents/Big Data Analytics Labs/precipitation-readings.csv\")\n",
    "\n",
    "L=prep.map(lambda line: line.split(\";\"))\n",
    "\n",
    "st = L.map(lambda x: ( (x[0],x[1]) ,float(x[3])) )\n",
    "\n",
    "max_st= st.reduceByKey(lambda x,y :x if x>=y else y)\n",
    "\n",
    "max_st=max_st.filter(lambda x: x[1]>=10. and x[1]<=20.)\n",
    "\n",
    "wst=max_st.map(lambda x: (x[0],float(x[1]) ))\n",
    "\n",
    "wst.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#st.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#station_temperature.join(st).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_temp_st.join(wst).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations=sc.textFile(\"C:/Users/quartermaine/Documents/Big Data Analytics Labs/stations-Ostergotland.csv\")\n",
    "precipitation=sc.textFile(\"C:/Users/quartermaine/Documents/Big Data Analytics Labs/precipitation-readings.csv\")\n",
    "\n",
    "stations=stations.map(lambda line: line.split(\";\"))\n",
    "precipitation=precipitation.map(lambda line:line.split(\";\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('1995', '08', '01', '103100'), 0.0),\n",
       " (('1995', '08', '01', '103100'), 0.0),\n",
       " (('1995', '08', '01', '103100'), 0.0),\n",
       " (('1995', '08', '01', '103100'), 0.0),\n",
       " (('1995', '08', '01', '103100'), 0.0),\n",
       " (('1995', '08', '01', '103100'), 0.0),\n",
       " (('1995', '08', '01', '103100'), 0.0),\n",
       " (('1995', '08', '01', '103100'), 0.0),\n",
       " (('1995', '08', '01', '103100'), 0.0),\n",
       " (('1995', '08', '01', '103100'), 0.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD = precipitation.map(lambda x: ( (x[1][0:4],x[1][5:7],x[1][8:10],x[0]),float(x[3]) ))\n",
    "\n",
    "RDD = RDD.filter(lambda x: int(x[0][0]) >= 1993 and int(x[0][0]) <= 2016)\n",
    "\n",
    "#############################\n",
    "\n",
    "#RDD_filtered=RDD.map(lambda x: (x[0][0],x[0][1], x[0][2],x[0][3],float(x[1]) ))\n",
    "\n",
    "RDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('2016', '07', '01', '99280'), 0.014285714285714287),\n",
       " (('2016', '07', '01', '98490'), 0.09999999999999999),\n",
       " (('2016', '07', '01', '98040'), 0.0),\n",
       " (('2016', '07', '01', '97530'), 0.62),\n",
       " (('2016', '07', '01', '97510'), 0.26),\n",
       " (('2016', '07', '01', '97370'), 0.02),\n",
       " (('2016', '07', '01', '97100'), 0.34285714285714286),\n",
       " (('2016', '07', '01', '96560'), 0.24285714285714288),\n",
       " (('2016', '07', '01', '96190'), 0.0),\n",
       " (('2016', '07', '01', '95540'), 0.0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mRDD = (RDD\n",
    "           .mapValues(lambda x: (x, 1))\n",
    "           .reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1]))\n",
    "           .mapValues(lambda x: x[0]/x[1]))\n",
    "mRDD.sortByKey(ascending=False).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('1993', '01', '154860'), 0.1295698924731183),\n",
       " (('1993', '01', '188790'), 0.017633333333333338),\n",
       " (('1993', '01', '97510'), 0.030277777777777775),\n",
       " (('1993', '02', '154860'), 0.033384387351778656),\n",
       " (('1993', '02', '188790'), 0.036128364389233954),\n",
       " (('1993', '02', '97510'), 0.02008281573498965),\n",
       " (('1993', '03', '154860'), 0.028341013824884784),\n",
       " (('1993', '03', '188790'), 0.07755921770297648),\n",
       " (('1993', '03', '97510'), 0.026113671274961593),\n",
       " (('1993', '04', '154860'), 0.006488957902001381)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M=mRDD.map(lambda x: ( (x[0][0],x[0][1],x[0][3]),x[1]) )\\\n",
    ".mapValues(lambda x: (x, 1))\\\n",
    ".reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1]))\\\n",
    ".mapValues(lambda x: x[0]/x[1]).sortByKey()\n",
    "M.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['84260',\n",
       " '85630',\n",
       " '85460',\n",
       " '85450',\n",
       " '85490',\n",
       " '85650',\n",
       " '85390',\n",
       " '85410',\n",
       " '86470',\n",
       " '86440',\n",
       " '86420',\n",
       " '86340',\n",
       " '86350',\n",
       " '86360',\n",
       " '86370',\n",
       " '86200',\n",
       " '86330',\n",
       " '87140',\n",
       " '87150',\n",
       " '86130',\n",
       " '86090',\n",
       " '85280',\n",
       " '85250',\n",
       " '85240',\n",
       " '85270',\n",
       " '85220',\n",
       " '85210',\n",
       " '85180',\n",
       " '85040',\n",
       " '85050',\n",
       " '75520',\n",
       " '85160',\n",
       " '85600',\n",
       " '85130']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_ost=sc.textFile(\"C:/Users/quartermaine/Documents/Big Data Analytics Labs/stations-Ostergotland.csv\")\n",
    "\n",
    "stations_ost=stations_ost.map(lambda line: line.split(\";\"))\n",
    "\n",
    "stations_ost.map(lambda x : x[0])\n",
    "stations_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\", line 235, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 409, in dump\n",
      "    self.save(obj)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 751, in save_tuple\n",
      "    save(element)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\", line 378, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\", line 529, in save_function_tuple\n",
      "    save(closure_values)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 781, in save_list\n",
      "    self._batch_appends(obj)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 805, in _batch_appends\n",
      "    save(x)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\", line 378, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\", line 529, in save_function_tuple\n",
      "    save(closure_values)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 781, in save_list\n",
      "    self._batch_appends(obj)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 805, in _batch_appends\n",
      "    save(x)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\", line 378, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\", line 529, in save_function_tuple\n",
      "    save(closure_values)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 781, in save_list\n",
      "    self._batch_appends(obj)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 808, in _batch_appends\n",
      "    save(tmp[0])\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\", line 378, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\", line 529, in save_function_tuple\n",
      "    save(closure_values)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 781, in save_list\n",
      "    self._batch_appends(obj)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 808, in _batch_appends\n",
      "    save(tmp[0])\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\", line 372, in save_function\n",
      "    self.save_function_tuple(obj)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\", line 525, in save_function_tuple\n",
      "    save(f_globals)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 476, in save\n",
      "    f(self, obj) # Call unbound method with explicit self\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 821, in save_dict\n",
      "    self._batch_setitems(obj.items())\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 852, in _batch_setitems\n",
      "    save(v)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\pickle.py\", line 496, in save\n",
      "    rv = reduce(self.proto)\n",
      "  File \"C:\\Users\\quartermaine\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\rdd.py\", line 228, in __getnewargs__\n",
      "    \"It appears that you are attempting to broadcast an RDD or reference an RDD from an \"\n",
      "Exception: It appears that you are attempting to broadcast an RDD or reference an RDD from an action or transformation. RDD transformations and actions can only be invoked by the driver, not inside of other transformations; for example, rdd1.map(lambda x: rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not serialize object: Exception: It appears that you are attempting to broadcast an RDD or reference an RDD from an action or transformation. RDD transformations and actions can only be invoked by the driver, not inside of other transformations; for example, rdd1.map(lambda x: rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    750\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[1;34m(self, obj, name)\u001b[0m\n\u001b[0;32m    377\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mklass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosure_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTUPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 781\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    804\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m                     \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[1;34m(self, obj, name)\u001b[0m\n\u001b[0;32m    377\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mklass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosure_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTUPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 781\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    804\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m                     \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAPPENDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[1;34m(self, obj, name)\u001b[0m\n\u001b[0;32m    377\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mklass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosure_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTUPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 781\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m                 \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAPPEND\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[1;34m(self, obj, name)\u001b[0m\n\u001b[0;32m    377\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mklass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosure_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTUPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_list\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 781\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_appends\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36m_batch_appends\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m                 \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAPPEND\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\u001b[0m in \u001b[0;36msave_function\u001b[1;34m(self, obj, name)\u001b[0m\n\u001b[0;32m    371\u001b[0m                 or themodule is None):\n\u001b[1;32m--> 372\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_function_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\u001b[0m in \u001b[0;36msave_function_tuple\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[1;31m# save the rest of the func data needed by _fill_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_globals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m         \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call unbound method with explicit self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    851\u001b[0m                 \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m                 \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSETITEM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\pickle.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0mrv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\rdd.py\u001b[0m in \u001b[0;36m__getnewargs__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    227\u001b[0m         raise Exception(\n\u001b[1;32m--> 228\u001b[1;33m             \u001b[1;34m\"It appears that you are attempting to broadcast an RDD or reference an RDD from an \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[1;34m\"action or transformation. RDD transformations and actions can only be invoked by the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: It appears that you are attempting to broadcast an RDD or reference an RDD from an action or transformation. RDD transformations and actions can only be invoked by the driver, not inside of other transformations; for example, rdd1.map(lambda x: rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-29f5340ec734>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mstations_ost\u001b[0m \u001b[1;32min\u001b[0m  \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\rdd.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m             \u001b[0mitems\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36mrunJob\u001b[1;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[1;31m# SparkContext#runJob.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m         \u001b[0msock_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\rdd.py\u001b[0m in \u001b[0;36m_jrdd\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m         wrapped_func = _wrap_function(self.ctx, self.func, self._prev_jrdd_deserializer,\n\u001b[1;32m-> 2489\u001b[1;33m                                       self._jrdd_deserializer, profiler)\n\u001b[0m\u001b[0;32m   2490\u001b[0m         python_rdd = self.ctx._jvm.PythonRDD(self._prev_jrdd.rdd(), wrapped_func,\n\u001b[0;32m   2491\u001b[0m                                              self.preservesPartitioning)\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\rdd.py\u001b[0m in \u001b[0;36m_wrap_function\u001b[1;34m(sc, func, deserializer, serializer, profiler)\u001b[0m\n\u001b[0;32m   2420\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mserializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"serializer should not be empty\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2421\u001b[0m     \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeserializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2422\u001b[1;33m     \u001b[0mpickled_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbroadcast_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincludes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_prepare_for_python_RDD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2423\u001b[0m     return sc._jvm.PythonFunction(bytearray(pickled_command), env, includes, sc.pythonExec,\n\u001b[0;32m   2424\u001b[0m                                   sc.pythonVer, broadcast_vars, sc._javaAccumulator)\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\rdd.py\u001b[0m in \u001b[0;36m_prepare_for_python_RDD\u001b[1;34m(sc, command)\u001b[0m\n\u001b[0;32m   2406\u001b[0m     \u001b[1;31m# the serialized command will be compressed by broadcast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2407\u001b[0m     \u001b[0mser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCloudPickleSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2408\u001b[1;33m     \u001b[0mpickled_command\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2409\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickled_command\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m<<\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 1M\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2410\u001b[0m         \u001b[1;31m# The broadcast will have same life cycle as created PythonRDD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\serializers.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, protocol)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m     \u001b[0mcp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCloudPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m     \u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\python3\\lib\\site-packages\\pyspark\\cloudpickle.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    247\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Could not serialize object: %s: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[0mprint_exec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPicklingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPicklingError\u001b[0m: Could not serialize object: Exception: It appears that you are attempting to broadcast an RDD or reference an RDD from an action or transformation. RDD transformations and actions can only be invoked by the driver, not inside of other transformations; for example, rdd1.map(lambda x: rdd2.values.count() * x) is invalid because the values transformation and count action cannot be performed inside of the rdd1.map transformation. For more information, see SPARK-5063."
     ]
    }
   ],
   "source": [
    "\n",
    "M.filter(lambda x : stations_ost in  x[0][2] ).take(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
