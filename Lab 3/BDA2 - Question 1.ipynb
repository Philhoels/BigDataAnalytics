{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Assignment 1 __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) What are the lowest and highest temperatures measured each year for the period 1950- 2014. Provide the lists sorted in the descending order with respect to the maximum temperature. In this exercise you will use the temperature-readings.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the setup\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, Row  \n",
    "from pyspark.sql import functions as F\n",
    "sc =SparkContext()\n",
    "sqlContext=SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_unifolder_temp_tiny = \"/Users/phillipholscher/OneDrive - LinkoÌˆpings universitet/LiU/Statistics and Machine Learning/Spring19T2/Big Data Analytics/Labs/Lab 2/temperature-readings-tiny.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and create rdd, this needs to be tranfsormed to data frame later on\n",
    "temps= sc.textFile(path_unifolder_temp_tiny)\n",
    "parts = temps.map(lambda l:l.split(\";\"))\n",
    "tempReadings = parts.map(lambda p: Row(station=p[0],  date=p[1], year=p[1].split(\"-\")[0], time=p[2],  Temp=float(p[3]), quality=p[4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Temp=6.8, date='2013-11-01', quality='G', station='102170', time='06:00:00', year='2013'),\n",
       " Row(Temp=3.8, date='2013-11-01', quality='G', station='102170', time='18:00:00', year='2013'),\n",
       " Row(Temp=5.8, date='2013-11-02', quality='G', station='102170', time='06:00:00', year='2013'),\n",
       " Row(Temp=-1.1, date='2013-11-02', quality='G', station='102170', time='18:00:00', year='2013'),\n",
       " Row(Temp=-0.2, date='2013-11-03', quality='G', station='102170', time='06:00:00', year='2013'),\n",
       " Row(Temp=5.6, date='2013-11-03', quality='G', station='102170', time='18:00:00', year='2013'),\n",
       " Row(Temp=6.5, date='2013-11-04', quality='G', station='102170', time='06:00:00', year='2013'),\n",
       " Row(Temp=5.1, date='2013-11-04', quality='G', station='102170', time='18:00:00', year='2013'),\n",
       " Row(Temp=4.2, date='2013-11-05', quality='G', station='102170', time='06:00:00', year='2013'),\n",
       " Row(Temp=3.2, date='2013-11-05', quality='G', station='102170', time='18:00:00', year='2013')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempReadings.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame from rdd\n",
    "schemaTempReadings =  sqlContext.createDataFrame(tempReadings)\n",
    "schemaTempReadings.registerTempTable(\"tempReadings\")\n",
    "schemaTempReadings.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-------+-------+--------+----+\n",
      "|Temp|      date|quality|station|    time|year|\n",
      "+----+----------+-------+-------+--------+----+\n",
      "| 6.8|2013-11-01|      G| 102170|06:00:00|2013|\n",
      "| 3.8|2013-11-01|      G| 102170|18:00:00|2013|\n",
      "| 5.8|2013-11-02|      G| 102170|06:00:00|2013|\n",
      "|-1.1|2013-11-02|      G| 102170|18:00:00|2013|\n",
      "|-0.2|2013-11-03|      G| 102170|06:00:00|2013|\n",
      "| 5.6|2013-11-03|      G| 102170|18:00:00|2013|\n",
      "| 6.5|2013-11-04|      G| 102170|06:00:00|2013|\n",
      "| 5.1|2013-11-04|      G| 102170|18:00:00|2013|\n",
      "| 4.2|2013-11-05|      G| 102170|06:00:00|2013|\n",
      "| 3.2|2013-11-05|      G| 102170|18:00:00|2013|\n",
      "+----+----------+-------+-------+--------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemaTempReadings.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|Temp|year|\n",
      "+----+----+\n",
      "| 6.8|2013|\n",
      "| 3.8|2013|\n",
      "| 5.8|2013|\n",
      "|-1.1|2013|\n",
      "|-0.2|2013|\n",
      "| 5.6|2013|\n",
      "| 6.5|2013|\n",
      "| 5.1|2013|\n",
      "| 4.2|2013|\n",
      "| 3.2|2013|\n",
      "+----+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we want to know the max and min temp for a specifitc time interval \n",
    "# time interval >= 1950 & <= 2014\n",
    "schemaTempReadings_filterd = schemaTempReadings.select([\"Temp\",\"year\"]).filter((schemaTempReadings[\"year\"] >= 1950) &  \n",
    "                                                                          (schemaTempReadings[\"year\"] <= 2014))\n",
    "schemaTempReadings_filterd.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|year|Temp_max|\n",
      "+----+--------+\n",
      "|1957|    25.2|\n",
      "|1956|    26.0|\n",
      "|1958|    28.1|\n",
      "|2014|    29.1|\n",
      "|2013|    10.2|\n",
      "|1959|    28.2|\n",
      "|1961|    19.0|\n",
      "|1955|    20.4|\n",
      "|1960|    29.0|\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the max temp for every year\n",
    "schemaTempReadings_max = schemaTempReadings_filterd.groupBy([\"year\"]).agg(F.max(\"Temp\").alias(\"Temp_max\"))\n",
    "schemaTempReadings_max.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|year|Temp_max|\n",
      "+----+--------+\n",
      "|2014|    29.1|\n",
      "|1960|    29.0|\n",
      "|1959|    28.2|\n",
      "|1958|    28.1|\n",
      "|1956|    26.0|\n",
      "|1957|    25.2|\n",
      "|1955|    20.4|\n",
      "|1961|    19.0|\n",
      "|2013|    10.2|\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# order the temp with respect to the maximum temperature\n",
    "schemaTempReadings_max_orderd = schemaTempReadings_max.sort(\"Temp_max\", ascending = False)\n",
    "schemaTempReadings_max_orderd.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|year|Temp_min|\n",
      "+----+--------+\n",
      "|1956|   -30.0|\n",
      "|1960|   -28.3|\n",
      "|1958|   -27.9|\n",
      "|1955|   -26.2|\n",
      "|2014|   -24.3|\n",
      "|1961|   -23.5|\n",
      "|1959|   -23.2|\n",
      "|1957|   -19.9|\n",
      "|2013|   -13.3|\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now we do the same for min temp\n",
    "schemaTempReadings_min = schemaTempReadings_filterd.groupBy([\"year\"]).agg(F.min(\"Temp\").alias(\"Temp_min\"))\\\n",
    ".sort(\"Temp_min\", ascending = True)\n",
    "schemaTempReadings_min.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
