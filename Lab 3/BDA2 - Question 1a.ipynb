{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Assignment 1__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Extend the program to include the station number (not the station name) where the maximum/minimum temperature was measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each question include the following data in the report and sort it as shown:\n",
    "- year, station with the max, maxValue ORDER BY maxValue DESC \n",
    "- year, station with the min, minValue ORDER BY minValue DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the setup\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, Row  \n",
    "from pyspark.sql import functions as F\n",
    "sc =SparkContext()\n",
    "sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_unifolder_temp_tiny = \"/Users/phillipholscher/OneDrive - LinkoÌˆpings universitet/LiU/Statistics and Machine Learning/Spring19T2/Big Data Analytics/Labs/Lab 2/temperature-readings-tiny.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and create rdd, this needs to be tranfsormed to data frame later on\n",
    "temps= sc.textFile(path_unifolder_temp_tiny)\n",
    "parts = temps.map(lambda l:l.split(\";\"))\n",
    "tempReadings = parts.map(lambda p: Row(station=p[0],  date=p[1], year=p[1].split(\"-\")[0], time=p[2],  Temp=float(p[3]), quality=p[4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Temp=6.8, date='2013-11-01', quality='G', station='102170', time='06:00:00', year='2013'),\n",
       " Row(Temp=3.8, date='2013-11-01', quality='G', station='102170', time='18:00:00', year='2013'),\n",
       " Row(Temp=5.8, date='2013-11-02', quality='G', station='102170', time='06:00:00', year='2013'),\n",
       " Row(Temp=-1.1, date='2013-11-02', quality='G', station='102170', time='18:00:00', year='2013'),\n",
       " Row(Temp=-0.2, date='2013-11-03', quality='G', station='102170', time='06:00:00', year='2013'),\n",
       " Row(Temp=5.6, date='2013-11-03', quality='G', station='102170', time='18:00:00', year='2013'),\n",
       " Row(Temp=6.5, date='2013-11-04', quality='G', station='102170', time='06:00:00', year='2013'),\n",
       " Row(Temp=5.1, date='2013-11-04', quality='G', station='102170', time='18:00:00', year='2013'),\n",
       " Row(Temp=4.2, date='2013-11-05', quality='G', station='102170', time='06:00:00', year='2013'),\n",
       " Row(Temp=3.2, date='2013-11-05', quality='G', station='102170', time='18:00:00', year='2013')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempReadings.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-------+-------+--------+----+\n",
      "|Temp|      date|quality|station|    time|year|\n",
      "+----+----------+-------+-------+--------+----+\n",
      "| 6.8|2013-11-01|      G| 102170|06:00:00|2013|\n",
      "| 3.8|2013-11-01|      G| 102170|18:00:00|2013|\n",
      "| 5.8|2013-11-02|      G| 102170|06:00:00|2013|\n",
      "|-1.1|2013-11-02|      G| 102170|18:00:00|2013|\n",
      "|-0.2|2013-11-03|      G| 102170|06:00:00|2013|\n",
      "| 5.6|2013-11-03|      G| 102170|18:00:00|2013|\n",
      "| 6.5|2013-11-04|      G| 102170|06:00:00|2013|\n",
      "| 5.1|2013-11-04|      G| 102170|18:00:00|2013|\n",
      "| 4.2|2013-11-05|      G| 102170|06:00:00|2013|\n",
      "| 3.2|2013-11-05|      G| 102170|18:00:00|2013|\n",
      "+----+----------+-------+-------+--------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a data frame from rdd\n",
    "schemaTempReadings =  sqlContext.createDataFrame(tempReadings)\n",
    "schemaTempReadings.registerTempTable(\"tempReadings\")\n",
    "schemaTempReadings.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-------+\n",
      "|Temp|year|station|\n",
      "+----+----+-------+\n",
      "| 6.8|2013| 102170|\n",
      "| 3.8|2013| 102170|\n",
      "| 5.8|2013| 102170|\n",
      "|-1.1|2013| 102170|\n",
      "|-0.2|2013| 102170|\n",
      "| 5.6|2013| 102170|\n",
      "| 6.5|2013| 102170|\n",
      "| 5.1|2013| 102170|\n",
      "| 4.2|2013| 102170|\n",
      "| 3.2|2013| 102170|\n",
      "+----+----+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we want to know the max and min temp for a specifitc time interval \n",
    "# time interval >= 1950 & <= 2014\n",
    "schemaTempReadings_filterd = schemaTempReadings.select([\"Temp\",\"year\", \"station\"]).filter((schemaTempReadings[\"year\"] >= 1950) &  \n",
    "                                                                          (schemaTempReadings[\"year\"] <= 2014))\n",
    "schemaTempReadings_filterd.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+--------+\n",
      "|year|station|Temp_max|\n",
      "+----+-------+--------+\n",
      "|2014| 102170|    29.1|\n",
      "|1960| 102190|    29.0|\n",
      "|1959| 102190|    28.2|\n",
      "|1958| 102190|    28.1|\n",
      "|1956| 102190|    26.0|\n",
      "|1957| 102190|    25.2|\n",
      "|1955| 102190|    20.4|\n",
      "|1961| 102190|    19.0|\n",
      "|2013| 102170|    10.2|\n",
      "+----+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# code from Question 1 + groupBy for station\n",
    "# max case\n",
    "temp_year_station_max = schemaTempReadings_filterd.groupBy([\"year\", \"station\"]).agg(F.max(\"Temp\").alias(\"Temp_max\"))\\\n",
    ".sort(\"Temp_max\", ascending = False)\n",
    "temp_year_station_max.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+--------+\n",
      "|year|station|Temp_min|\n",
      "+----+-------+--------+\n",
      "|1956| 102190|   -30.0|\n",
      "|1960| 102190|   -28.3|\n",
      "|1958| 102190|   -27.9|\n",
      "|1955| 102190|   -26.2|\n",
      "|2014| 102170|   -24.3|\n",
      "|1961| 102190|   -23.5|\n",
      "|1959| 102190|   -23.2|\n",
      "|1957| 102190|   -19.9|\n",
      "|2013| 102170|   -13.3|\n",
      "+----+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# code from Question 1 + groupBy for station\n",
    "# min case\n",
    "temp_year_station_min = schemaTempReadings_filterd.groupBy([\"year\", \"station\"]).agg(F.min(\"Temp\").alias(\"Temp_min\"))\\\n",
    ".sort(\"Temp_min\", ascending = True)\n",
    "temp_year_station_min.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
